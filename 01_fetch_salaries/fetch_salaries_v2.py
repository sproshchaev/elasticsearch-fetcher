# v2 —Å –¥–æ–ø. –∏–Ω–¥–∏–∫–∞—Ü–∏–µ–π –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
import requests
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
ES_URL = "http://10.0.5.41:9200"  # URL Elasticsearch
INDEX = "indeed_job_page"         # –∏–Ω–¥–µ–∫—Å
BATCH_SIZE = 1000                 # –†–∞–∑–º–µ—Ä –ø–æ—Ä—Ü–∏–∏ (size) –¥–ª—è –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ –ø–æ–ª—É—á–µ–Ω–∏—è

# –í—ã–±–æ—Ä–∫–∞ —Å—Ç—Ä–∞–Ω
COUNTRIES = ["PK", "MY", "ZA", "PE", "PH", "ID", "US", "QA", "TH", "SA"]
# COUNTRIES = ["QA", "SA", "TH"]


def fetch_all_salaries_by_country(country_code):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è rowSalary –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω—ã.
    """
    all_salaries = []
    search_after = None
    page_count = 0

    print(f"  ‚û§ –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {country_code}...")

    while True:
        page_count += 1
        print(f"    –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_count}...", end='\r')  # –í—ã–≤–æ–¥–∏–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
        query_body = {
            "_source": ["rowSalary"],
            "query": {
                "bool": {
                    "filter": [
                        {
                            "term": {
                                "loc.country_code.keyword": country_code
                            }
                        },
                        {
                            "exists": {
                                "field": "rowSalary"
                            }
                        }
                    ]
                }
            },
            "sort": [
                {
                    "id.keyword": {
                        "order": "asc"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º asc, —á—Ç–æ–±—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞–±–æ—Ç–∞–ª search_after
                    }
                }
            ],
            "size": BATCH_SIZE
        }

        if search_after:
            query_body["search_after"] = search_after

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        response = requests.post(
            f"{ES_URL}/{INDEX}/_search",
            headers={"Content-Type": "application/json"},
            data=json.dumps(query_body)
        )

        if response.status_code != 200:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –¥–ª—è —Å—Ç—Ä–∞–Ω—ã {country_code}: {response.status_code}, {response.text}")
            break

        result = response.json()

        hits = result.get("hits", {}).get("hits", [])
        if not hits:
            print(f"\n‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è {country_code} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ù–∞–π–¥–µ–Ω–æ {len(all_salaries)} –∑–∞–ø–∏—Å–µ–π.")
            break

        # –ò–∑–≤–ª–µ–∫–∞–µ–º rowSalary
        for hit in hits:
            source = hit.get("_source", {})
            salary = source.get("rowSalary")
            if salary:
                all_salaries.append(salary)

        # –û–±–Ω–æ–≤–ª—è–µ–º search_after
        last_hit = hits[-1]
        search_after = last_hit.get("sort")

    return all_salaries

def save_salaries_to_file(country_code, salaries):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞—Ä–ø–ª–∞—Ç –≤ —Ñ–∞–π–ª.
    """
    filename = f"rowSalaries_{country_code}.txt"
    with open(filename, "w", encoding="utf-8") as f:
        for salary in salaries:
            f.write(salary + "\n")
    print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(salaries)} –∑–∞–ø–∏—Å–µ–π –≤ {filename}")

def main():
    for country in COUNTRIES:
        print(f"\nüöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω—ã: {country}")
        salaries = fetch_all_salaries_by_country(country)
        save_salaries_to_file(country, salaries)

if __name__ == "__main__":
    main()